
# **Introduction**

## What is this

This notebook will include informal meta-analyses of different metrics and methods
for evaluating surgical skill.


>**The reported metrics compare differences between novices and expert surgeons.**


It is informal because it's not based on systematic review,
and because some studies have been included with very relaxed conditions. For example,
I have picked the novices and experts without comparing their definitions between studies. 
Novice = weakest skill group in the study, expert = strongest skill group in the study.
If a study included more than 2 groups, I picked the weakest (=novice) and strongest (=expert)
groups' results and discarded the others. If a study included more than 1 task, or several sub-tasks, I picked the one with largest difference between groups.

**Many papers did report means and standard deviations explicitly, so they had to be estimated from boxplots/barplots, or by some other means**

For example, sometimes studies reported only mean or median, but no SE/SD. I estimated the SD/SE in those cases based e.g. on the SD of some other similar metric that they reported, or the SD of previous results for the same metric. **See the excel file for notes on each study.**

May or may not be turned into more systematic meta-analysis later.

Example metrics that will be most likely included (Bolded ones have priority)

- **Task time**
- **Tool Path length**
- Tool Velocity
- Tool Acceleration
- Tool Curvature
- **Idle time**
- **Pupil dilations**
- **Blinks**
- **Tool Movement efficiency**
- **Number of movements**
- Tool Forces
- Tool Torques
- **Bimanual dexterity**
- **Jerk**
- Fixation duration
- Saccade amplitudes
- EEG?
- **Surgical Evaluation Instruments (SEI)**

Full list of papers and metrics can be found in the excel file shared in the repo:

[Link to Github repo](https://github.com/jpkos/surg-mveta)

*Last update: 20.6.2022.*

## Submit results

If you notice errors or know some good studies to be included, feel free to forward them to

jani.koskinen [ at ] uef.fi

or use the form below TBD
<!--
<iframe src="https://docs.google.com/forms/d/e/1FAIpQLSdZQOqK2r6j1hXMFhraIdsLXZebgS8va0-Vbv7-v5_eSoiBSg/viewform?embedded=true" width="640" height="640" frameborder="0" marginheight="0" marginwidth="0">Loadingâ€¦</iframe> -->


## How results are calculated

1. From each study, extract
  + Number of trials per group (Nn, Ne, for novices and experts, respectively)
  + Means per group (Mn, Me for novices and experts, respectively)
  + Standard deviations per group (SDn, SDe)
2. Calculate pooled standard deviation SDpooled
3. Normalize by calculating Standardized Mean Difference (SDM): (Mn - Me)/SDpooled
4. Calculate small sample size correction g = SMD*(1 - 3/(4n - 9)), where n is the total sample size of the study (both groups combined).
5. Calculate SDg, standard deviation after correction

These values are used as input in the R *meta* package's metagen function.

For more information, check:

[Doing Meta-Analysis with R: A Hands-On Guide](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/)

## Forest plots

![Forest plot explanation](figures/forest-explanation.png)

## Sample size estimation


```{r, results='hide', message=FALSE, echo=FALSE, warning=FALSE}
library(pwr)
library(ggplot2)
library(plotly)
```

How many samples needed at some effect size d? At alpha = 0.05 and power = 0.8 and using t-test. Assuming independent trials (e.g. no multiple measurements from same participants etc.)

```{r, results='hide', message=FALSE, echo=FALSE, warning=FALSE}
i <- 1
ds <- seq(0.3,4,0.05)
ns <- list()
for (d in ds){
  poweranalysis <- pwr.t.test(d=d, sig.level=0.05, power=0.8)
  ns[i] <- poweranalysis$n
  i <- i + 1
}
df.sample <- data.frame(cbind(as.numeric(ns), as.numeric(ds)))
colnames(df.sample) <- c("sample_size", "effect_size")
```

Hover mouse over the points in the plot to see the values. **Sample size is for group, so you need this many samples per group**

Some baseline effect sizes from the meta-analyses given as baseline:

IT = Idle Time

TT = Task Time

BD = Bimanual Dexterity

TEPR = Task-Evoked Pupil Reaction/Dilation (Esimated without one outlier study removed)

TJ = Tool Jerk

TF = Tool Force

```{r, warning=FALSE, message=FALSE, echo=FALSE}
p <- ggplot(data=df.sample, aes(x=effect_size, y=sample_size)) + geom_point() + scale_y_continuous(breaks = scales::pretty_breaks(n = 20)) + scale_x_continuous(breaks = scales::pretty_breaks(n = 20)) + labs(x="Effect size d", y="Sample size n") + 
  geom_vline(xintercept=2.5, color='red') + annotate("text", x=2.6, y=150, label="TT", color='red') +
  geom_vline(xintercept=1.4, color='red') + annotate("text", x=1.5, y=150, label="IT", color='red') + 
  geom_vline(xintercept=3.3, color='red') + annotate("text", x=3.4, y=150, label="BD", color='red') +
  geom_vline(xintercept=0.6, color='red') + annotate("text", x=0.7, y=150, label="TEPR", color='red') + 
  geom_vline(xintercept=0.7, color='red') + annotate("text", x=0.8, y=170, label="TJ", color='red') +
  geom_vline(xintercept=1.6, color='red') + annotate("text", x=1.7, y=170, label="TF", color='red') 

ggplotly(p)
```



